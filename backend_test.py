#!/usr/bin/env python3
"""
VisionForge Backend Testing Suite
Tests Ollama integration and all API endpoints
"""

import asyncio
import aiohttp
import json
import base64
import os
import sys
from pathlib import Path
import tempfile
from PIL import Image
import io

# Test configuration
BACKEND_URL = "https://storycraft-102.preview.emergentagent.com/api"
TEST_IMAGE_SIZE = (256, 256)

class VisionForgeBackendTester:
    def __init__(self):
        self.session = None
        self.test_results = []
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def log_result(self, test_name: str, success: bool, message: str, details: dict = None):
        """Log test result"""
        result = {
            "test": test_name,
            "success": success,
            "message": message,
            "details": details or {}
        }
        self.test_results.append(result)
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status} {test_name}: {message}")
        if details and not success:
            print(f"   Details: {details}")
    
    def create_test_image(self) -> bytes:
        """Create a simple test image"""
        # Create a simple colored image for testing
        img = Image.new('RGB', TEST_IMAGE_SIZE, color='blue')
        # Add some simple shapes to make it more interesting
        from PIL import ImageDraw
        draw = ImageDraw.Draw(img)
        draw.rectangle([50, 50, 150, 150], fill='red')
        draw.ellipse([100, 100, 200, 200], fill='green')
        
        # Convert to bytes
        img_bytes = io.BytesIO()
        img.save(img_bytes, format='JPEG')
        return img_bytes.getvalue()
    
    async def test_health_check(self):
        """Test basic API health check at /api/"""
        try:
            async with self.session.get(f"{BACKEND_URL}/") as response:
                if response.status == 200:
                    data = await response.json()
                    if "message" in data and "VisionForge" in data["message"]:
                        self.log_result("Health Check", True, "API is responding correctly", data)
                    else:
                        self.log_result("Health Check", False, "Unexpected response format", data)
                else:
                    self.log_result("Health Check", False, f"HTTP {response.status}", {"status": response.status})
        except Exception as e:
            self.log_result("Health Check", False, f"Connection error: {str(e)}")
    
    async def test_get_genres(self):
        """Test get available genres at /api/genres"""
        try:
            async with self.session.get(f"{BACKEND_URL}/genres") as response:
                if response.status == 200:
                    data = await response.json()
                    if "genres" in data and isinstance(data["genres"], dict):
                        genre_count = len(data["genres"])
                        sample_genres = list(data["genres"].keys())[:3]
                        self.log_result("Get Genres", True, f"Retrieved {genre_count} genres", 
                                      {"sample_genres": sample_genres, "total_count": genre_count})
                    else:
                        self.log_result("Get Genres", False, "Invalid genres response format", data)
                else:
                    self.log_result("Get Genres", False, f"HTTP {response.status}", {"status": response.status})
        except Exception as e:
            self.log_result("Get Genres", False, f"Request error: {str(e)}")
    
    async def test_image_analysis(self):
        """Test image analysis functionality at /api/analyze-image (core feature)"""
        try:
            # Create test image
            test_image = self.create_test_image()
            
            # Prepare multipart form data
            data = aiohttp.FormData()
            data.add_field('file', test_image, filename='test_image.jpg', content_type='image/jpeg')
            data.add_field('genre', 'urban_realistic')
            data.add_field('origin', 'nootropic_enhanced')
            data.add_field('social_status', 'entrepreneurial')
            data.add_field('power_source', 'nootropic_drug')
            data.add_field('evolution_stage', 'synergistic')
            data.add_field('geographic_context', 'detroit')
            data.add_field('op_mode', 'false')
            
            async with self.session.post(f"{BACKEND_URL}/analyze-image", data=data) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get("success") and "analysis" in data:
                        analysis = data["analysis"]
                        # Check for key components of analysis
                        has_traits = "traits" in analysis and len(analysis["traits"]) > 0
                        has_powers = "power_suggestions" in analysis and len(analysis["power_suggestions"]) > 0
                        has_backstory = "backstory_seeds" in analysis and len(analysis["backstory_seeds"]) > 0
                        has_persona = "persona_summary" in analysis and analysis["persona_summary"]
                        
                        if has_traits and has_powers and has_backstory and has_persona:
                            self.log_result("Image Analysis (LLaVA)", True, "Complete character analysis generated", {
                                "traits_count": len(analysis["traits"]),
                                "powers_count": len(analysis["power_suggestions"]),
                                "backstory_seeds": len(analysis["backstory_seeds"]),
                                "has_persona": bool(analysis["persona_summary"])
                            })
                        else:
                            self.log_result("Image Analysis (LLaVA)", False, "Incomplete analysis response", {
                                "has_traits": has_traits,
                                "has_powers": has_powers,
                                "has_backstory": has_backstory,
                                "has_persona": has_persona
                            })
                    else:
                        self.log_result("Image Analysis (LLaVA)", False, "Invalid response format", data)
                else:
                    error_text = await response.text()
                    self.log_result("Image Analysis (LLaVA)", False, f"HTTP {response.status}", {"error": error_text})
        except Exception as e:
            self.log_result("Image Analysis (LLaVA)", False, f"Request error: {str(e)}")
    
    async def test_text_generation(self):
        """Test text generation at /api/generate-text with Llama3.2"""
        try:
            test_payload = {
                "prompt": "Create a compelling backstory for a cyberpunk hacker who discovered they have telepathic abilities",
                "generation_type": "backstory",
                "style_preferences": {"tone": "gritty", "length": "medium"}
            }
            
            async with self.session.post(f"{BACKEND_URL}/generate-text", 
                                       json=test_payload,
                                       headers={"Content-Type": "application/json"}) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get("success") and "generated_text" in data:
                        generated_text = data["generated_text"]
                        text_length = len(generated_text)
                        has_cliche_score = "cliche_score" in data
                        
                        if text_length > 50:  # Reasonable minimum length
                            self.log_result("Text Generation (Llama3.2)", True, "Creative text generated successfully", {
                                "text_length": text_length,
                                "cliche_score": data.get("cliche_score", "N/A"),
                                "has_suggestions": bool(data.get("suggestions"))
                            })
                        else:
                            self.log_result("Text Generation (Llama3.2)", False, "Generated text too short", {
                                "text_length": text_length,
                                "text_preview": generated_text[:100]
                            })
                    else:
                        self.log_result("Text Generation (Llama3.2)", False, "Invalid response format", data)
                else:
                    error_text = await response.text()
                    self.log_result("Text Generation (Llama3.2)", False, f"HTTP {response.status}", {"error": error_text})
        except Exception as e:
            self.log_result("Text Generation (Llama3.2)", False, f"Request error: {str(e)}")
    
    async def test_style_analysis(self):
        """Test style analysis at /api/analyze-style"""
        try:
            test_text = """The mysterious figure delved into the enigmatic tapestry of shadows, 
            their meticulous movements betraying a hidden agenda. The ancient prophecy spoke of 
            a chosen one who would manipulate the very fabric of reality through their kinetic abilities."""
            
            test_payload = {
                "text": test_text
            }
            
            async with self.session.post(f"{BACKEND_URL}/analyze-style",
                                       json=test_payload,
                                       headers={"Content-Type": "application/json"}) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get("success") and "cliche_score" in data:
                        cliche_score = data["cliche_score"]
                        has_issues = "issues" in data and len(data["issues"]) > 0
                        has_suggestions = "suggestions" in data and len(data["suggestions"]) > 0
                        
                        # The test text contains many clich√©s, so we expect a high score
                        if cliche_score > 0.3:  # Should detect the clich√©s
                            self.log_result("Style Analysis", True, "Clich√© detection working correctly", {
                                "cliche_score": cliche_score,
                                "issues_found": len(data.get("issues", [])),
                                "suggestions_provided": len(data.get("suggestions", []))
                            })
                        else:
                            self.log_result("Style Analysis", False, "Failed to detect obvious clich√©s", {
                                "cliche_score": cliche_score,
                                "expected": "> 0.3"
                            })
                    else:
                        self.log_result("Style Analysis", False, "Invalid response format", data)
                else:
                    error_text = await response.text()
                    self.log_result("Style Analysis", False, f"HTTP {response.status}", {"error": error_text})
        except Exception as e:
            self.log_result("Style Analysis", False, f"Request error: {str(e)}")
    
    async def test_analyses_history(self):
        """Test history endpoint at /api/analyses"""
        try:
            async with self.session.get(f"{BACKEND_URL}/analyses") as response:
                if response.status == 200:
                    data = await response.json()
                    if isinstance(data, list):
                        analysis_count = len(data)
                        # Check if we have any analyses and if they have expected structure
                        if analysis_count > 0:
                            sample_analysis = data[0]
                            has_id = "id" in sample_analysis
                            has_created_at = "created_at" in sample_analysis
                            
                            self.log_result("Analyses History", True, f"Retrieved {analysis_count} analyses", {
                                "count": analysis_count,
                                "has_proper_structure": has_id and has_created_at,
                                "sample_keys": list(sample_analysis.keys())[:5]
                            })
                        else:
                            self.log_result("Analyses History", True, "Empty analyses list (expected for new system)", {
                                "count": 0
                            })
                    else:
                        self.log_result("Analyses History", False, "Response is not a list", {"type": type(data).__name__})
                else:
                    error_text = await response.text()
                    self.log_result("Analyses History", False, f"HTTP {response.status}", {"error": error_text})
        except Exception as e:
            self.log_result("Analyses History", False, f"Request error: {str(e)}")
    
    async def test_ollama_models_availability(self):
        """Test if Ollama models are available and responding"""
        try:
            # Test a simple text generation to verify Llama3.2 is working
            simple_payload = {
                "prompt": "Hello, this is a test. Please respond with 'Ollama is working correctly.'",
                "generation_type": "character"
            }
            
            async with self.session.post(f"{BACKEND_URL}/generate-text",
                                       json=simple_payload,
                                       headers={"Content-Type": "application/json"}) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get("success") and "generated_text" in data:
                        response_text = data["generated_text"].lower()
                        if "ollama" in response_text or len(data["generated_text"]) > 10:
                            self.log_result("Ollama Models Availability", True, "Ollama models responding", {
                                "llama3.2_status": "working",
                                "response_length": len(data["generated_text"])
                            })
                        else:
                            self.log_result("Ollama Models Availability", False, "Unexpected model response", {
                                "response": data["generated_text"]
                            })
                    else:
                        self.log_result("Ollama Models Availability", False, "No text generated", data)
                else:
                    self.log_result("Ollama Models Availability", False, f"HTTP {response.status}")
        except Exception as e:
            self.log_result("Ollama Models Availability", False, f"Model test error: {str(e)}")
    
    async def test_beat_sheet_types(self):
        """Test beat sheet types endpoint at /api/beat-sheet-types"""
        try:
            async with self.session.get(f"{BACKEND_URL}/beat-sheet-types") as response:
                if response.status == 200:
                    data = await response.json()
                    if "sheet_types" in data and "tone_pacing" in data:
                        sheet_types = data["sheet_types"]
                        tone_pacing = data["tone_pacing"]
                        
                        # Verify expected sheet types
                        expected_types = ["save_the_cat", "dan_harmon", "three_act", "hero_journey", "kish≈çtenketsu"]
                        available_types = [st["value"] for st in sheet_types]
                        
                        # Verify expected tone pacing options
                        expected_pacing = ["slow_burn", "standard", "fast_paced", "explosive"]
                        available_pacing = [tp["value"] for tp in tone_pacing]
                        
                        types_match = all(t in available_types for t in expected_types)
                        pacing_match = all(p in available_pacing for p in expected_pacing)
                        
                        if types_match and pacing_match:
                            self.log_result("Beat Sheet Types", True, "All expected types and pacing options available", {
                                "sheet_types_count": len(sheet_types),
                                "tone_pacing_count": len(tone_pacing),
                                "available_types": available_types,
                                "available_pacing": available_pacing
                            })
                        else:
                            self.log_result("Beat Sheet Types", False, "Missing expected types or pacing options", {
                                "types_match": types_match,
                                "pacing_match": pacing_match,
                                "available_types": available_types,
                                "available_pacing": available_pacing
                            })
                    else:
                        self.log_result("Beat Sheet Types", False, "Invalid response format", data)
                else:
                    error_text = await response.text()
                    self.log_result("Beat Sheet Types", False, f"HTTP {response.status}", {"error": error_text})
        except Exception as e:
            self.log_result("Beat Sheet Types", False, f"Request error: {str(e)}")
    
    async def test_beat_sheet_generation(self):
        """Test beat sheet generation at /api/generate-beat-sheet"""
        try:
            # Test with different sheet types and configurations
            test_configs = [
                {
                    "sheet_type": "save_the_cat",
                    "tone_pacing": "standard",
                    "story_length": 110,
                    "character_data": {
                        "character_origin": "nootropic_enhanced",
                        "power_source": "nootropic_drug",
                        "social_status": "entrepreneurial",
                        "traits": [{"trait": "Strategic mastermind with enhanced cognition"}],
                        "backstory_seeds": ["Former entrepreneur who gained cognitive enhancement"],
                        "power_suggestions": [{"name": "Hypercognitive Processing", "description": "Enhanced mental processing"}]
                    }
                },
                {
                    "sheet_type": "dan_harmon",
                    "tone_pacing": "fast_paced",
                    "story_length": 90
                },
                {
                    "sheet_type": "three_act",
                    "tone_pacing": "explosive",
                    "story_length": 120
                }
            ]
            
            success_count = 0
            for i, config in enumerate(test_configs):
                try:
                    async with self.session.post(f"{BACKEND_URL}/generate-beat-sheet",
                                               json=config,
                                               headers={"Content-Type": "application/json"}) as response:
                        if response.status == 200:
                            data = await response.json()
                            if data.get("success") and "beat_sheet" in data:
                                beat_sheet = data["beat_sheet"]
                                
                                # Verify beat sheet structure
                                required_fields = ["sheet_type", "title", "description", "total_beats", "beats"]
                                has_required = all(field in beat_sheet for field in required_fields)
                                
                                # Verify beats structure
                                beats = beat_sheet.get("beats", [])
                                valid_beats = all(
                                    all(field in beat for field in ["beat_number", "beat_name", "description", "page_range"])
                                    for beat in beats
                                ) if beats else False
                                
                                if has_required and valid_beats and len(beats) > 0:
                                    success_count += 1
                                    self.log_result(f"Beat Sheet Generation ({config['sheet_type']})", True, 
                                                  f"Generated {len(beats)} beats successfully", {
                                                      "sheet_type": beat_sheet["sheet_type"],
                                                      "total_beats": beat_sheet["total_beats"],
                                                      "estimated_pages": beat_sheet.get("estimated_pages", "N/A"),
                                                      "has_character_integration": bool(config.get("character_data"))
                                                  })
                                else:
                                    self.log_result(f"Beat Sheet Generation ({config['sheet_type']})", False, 
                                                  "Invalid beat sheet structure", {
                                                      "has_required_fields": has_required,
                                                      "valid_beats": valid_beats,
                                                      "beats_count": len(beats)
                                                  })
                            else:
                                self.log_result(f"Beat Sheet Generation ({config['sheet_type']})", False, 
                                              "Invalid response format", data)
                        else:
                            error_text = await response.text()
                            self.log_result(f"Beat Sheet Generation ({config['sheet_type']})", False, 
                                          f"HTTP {response.status}", {"error": error_text})
                except Exception as e:
                    self.log_result(f"Beat Sheet Generation ({config['sheet_type']})", False, 
                                  f"Request error: {str(e)}")
            
            # Overall beat sheet generation result
            if success_count == len(test_configs):
                self.log_result("Beat Sheet Generation (Overall)", True, 
                              f"All {success_count} configurations successful", {
                                  "tested_configs": len(test_configs),
                                  "successful": success_count
                              })
            else:
                self.log_result("Beat Sheet Generation (Overall)", False, 
                              f"Only {success_count}/{len(test_configs)} configurations successful", {
                                  "tested_configs": len(test_configs),
                                  "successful": success_count
                              })
                
        except Exception as e:
            self.log_result("Beat Sheet Generation (Overall)", False, f"Test setup error: {str(e)}")
    
    async def test_trope_risk_analysis(self):
        """Test trope risk analysis at /api/analyze-trope-risk - CRITICAL: Test timeout fixes"""
        import time
        try:
            # Test with sophisticated Marcus-style character
            sophisticated_character = {
                "id": "test-character-sophisticated",
                "character_origin": "nootropic_enhanced",
                "power_source": "nootropic_drug",
                "social_status": "entrepreneurial",
                "geographic_context": "detroit",
                "archetype_tags": ["System Changer", "Power Broker"],
                "traits": [
                    {"trait": "Strategic mastermind with enhanced cognition"},
                    {"trait": "Systematic empire builder"}
                ],
                "backstory_seeds": [
                    "Former entrepreneur who gained cognitive enhancement",
                    "Uses intelligence to navigate complex power structures"
                ],
                "power_suggestions": [
                    {"name": "Hypercognitive Processing", "description": "Enhanced mental processing speed", "cost_level": 8},
                    {"name": "Strategic Network Analysis", "description": "Analyzes social and business networks", "cost_level": 7}
                ]
            }
            
            # Test with clich√©d character for comparison
            cliched_character = {
                "id": "test-character-cliched",
                "character_origin": "human",
                "power_source": "magic",
                "traits": [{"trait": "Mysterious past"}],
                "backstory_seeds": ["Orphaned hero with dark past", "Chosen one destined to save world"],
                "power_suggestions": [
                    {"name": "Fire Control", "description": "Controls fire elements", "cost_level": 5},
                    {"name": "Super Strength", "description": "Incredible physical strength", "cost_level": 6}
                ]
            }
            
            test_characters = [
                ("Sophisticated Character", sophisticated_character),
                ("Clich√©d Character", cliched_character)
            ]
            
            for char_name, character_data in test_characters:
                try:
                    test_payload = {"character_data": character_data}
                    
                    # CRITICAL: Monitor response time to verify timeout fixes
                    start_time = time.time()
                    
                    # Set client timeout to 35 seconds (should complete within 30 seconds per requirement)
                    timeout = aiohttp.ClientTimeout(total=35)
                    
                    async with self.session.post(f"{BACKEND_URL}/analyze-trope-risk",
                                               json=test_payload,
                                               headers={"Content-Type": "application/json"},
                                               timeout=timeout) as response:
                        
                        end_time = time.time()
                        response_time = end_time - start_time
                        
                        if response.status == 200:
                            data = await response.json()
                            if data.get("success") and "trope_analysis" in data:
                                analysis = data["trope_analysis"]
                                
                                # Verify analysis structure
                                required_fields = ["overall_freshness_score", "marcus_level_rating", "trope_analyses", 
                                                 "improvement_suggestions", "freshness_rating"]
                                has_required = all(field in analysis for field in required_fields)
                                
                                # Verify trope analyses structure
                                trope_analyses = analysis.get("trope_analyses", [])
                                valid_tropes = all(
                                    all(field in trope for field in ["trope_name", "cliche_score", "freshness_level"])
                                    for trope in trope_analyses
                                ) if trope_analyses else True  # Empty is valid
                                
                                freshness_score = analysis.get("overall_freshness_score", 0)
                                marcus_rating = analysis.get("marcus_level_rating", 0)
                                
                                # CRITICAL: Verify timeout fix - should complete within 30 seconds
                                timeout_fixed = response_time <= 30.0
                                
                                if has_required and valid_tropes and timeout_fixed:
                                    self.log_result(f"Trope Risk Analysis ({char_name})", True, 
                                                  f"Analysis completed in {response_time:.1f}s (timeout fix working)", {
                                                      "response_time_seconds": round(response_time, 2),
                                                      "timeout_requirement_met": timeout_fixed,
                                                      "freshness_score": round(freshness_score, 3),
                                                      "marcus_rating": round(marcus_rating, 3),
                                                      "freshness_rating": analysis.get("freshness_rating"),
                                                      "tropes_found": len(trope_analyses),
                                                      "has_suggestions": len(analysis.get("improvement_suggestions", [])) > 0
                                                  })
                                elif not timeout_fixed:
                                    self.log_result(f"Trope Risk Analysis ({char_name})", False, 
                                                  f"TIMEOUT ISSUE: Response took {response_time:.1f}s (>30s limit)", {
                                                      "response_time_seconds": round(response_time, 2),
                                                      "timeout_requirement_met": False,
                                                      "timeout_limit": 30.0
                                                  })
                                else:
                                    self.log_result(f"Trope Risk Analysis ({char_name})", False, 
                                                  f"Invalid analysis structure (completed in {response_time:.1f}s)", {
                                                      "response_time_seconds": round(response_time, 2),
                                                      "has_required_fields": has_required,
                                                      "valid_tropes": valid_tropes,
                                                      "tropes_count": len(trope_analyses)
                                                  })
                            else:
                                self.log_result(f"Trope Risk Analysis ({char_name})", False, 
                                              f"Invalid response format (completed in {response_time:.1f}s)", {
                                                  "response_time_seconds": round(response_time, 2),
                                                  "response_data": data
                                              })
                        else:
                            error_text = await response.text()
                            self.log_result(f"Trope Risk Analysis ({char_name})", False, 
                                          f"HTTP {response.status} after {response_time:.1f}s", {
                                              "response_time_seconds": round(response_time, 2),
                                              "error": error_text
                                          })
                            
                except asyncio.TimeoutError:
                    self.log_result(f"Trope Risk Analysis ({char_name})", False, 
                                  "CRITICAL: Request timed out (>35s) - timeout fixes not working", {
                                      "timeout_seconds": 35,
                                      "issue": "Ollama enhancement still causing delays"
                                  })
                except Exception as e:
                    self.log_result(f"Trope Risk Analysis ({char_name})", False, 
                                  f"Request error: {str(e)}")
                    
        except Exception as e:
            self.log_result("Trope Risk Analysis (Overall)", False, f"Test setup error: {str(e)}")
    
    async def test_power_system_themes(self):
        """Test power system themes endpoint at /api/power-system-themes"""
        try:
            async with self.session.get(f"{BACKEND_URL}/power-system-themes") as response:
                if response.status == 200:
                    data = await response.json()
                    if "themes" in data and isinstance(data["themes"], list):
                        themes = data["themes"]
                        
                        # Verify expected themes (6 narrative themes)
                        expected_theme_ids = [
                            "identity_crisis", "power_corruption", "inherited_trauma",
                            "technological_anxiety", "social_stratification", "existential_purpose"
                        ]
                        
                        available_theme_ids = [theme["id"] for theme in themes]
                        themes_match = all(theme_id in available_theme_ids for theme_id in expected_theme_ids)
                        
                        # Verify theme structure
                        valid_structure = all(
                            all(field in theme for field in ["id", "name", "description", "examples"])
                            for theme in themes
                        ) if themes else False
                        
                        if themes_match and valid_structure and len(themes) == 6:
                            self.log_result("Power System Themes", True, "All 6 narrative themes available", {
                                "themes_count": len(themes),
                                "available_themes": available_theme_ids,
                                "structure_valid": valid_structure
                            })
                        else:
                            self.log_result("Power System Themes", False, "Missing expected themes or invalid structure", {
                                "expected_count": 6,
                                "actual_count": len(themes),
                                "themes_match": themes_match,
                                "structure_valid": valid_structure,
                                "available_themes": available_theme_ids
                            })
                    else:
                        self.log_result("Power System Themes", False, "Invalid response format", data)
                else:
                    error_text = await response.text()
                    self.log_result("Power System Themes", False, f"HTTP {response.status}", {"error": error_text})
        except Exception as e:
            self.log_result("Power System Themes", False, f"Request error: {str(e)}")
    
    async def test_power_system_generation(self):
        """Test advanced power system generation at /api/generate-power-system"""
        try:
            # Test configurations as specified in the review request
            test_configs = [
                {
                    "name": "Simple Request (Default)",
                    "payload": {}
                },
                {
                    "name": "With Theme",
                    "payload": {
                        "narrative_focus": "power_corruption",
                        "complexity_level": "moderate"
                    }
                },
                {
                    "name": "With Character Context",
                    "payload": {
                        "character_context": {
                            "character_origin": "enhanced",
                            "social_status": "entrepreneur"
                        },
                        "complexity_level": "complex"
                    }
                }
            ]
            
            success_count = 0
            for config in test_configs:
                try:
                    async with self.session.post(f"{BACKEND_URL}/generate-power-system",
                                               json=config["payload"],
                                               headers={"Content-Type": "application/json"}) as response:
                        if response.status == 200:
                            data = await response.json()
                            if data.get("success") and "power_system" in data:
                                power_system = data["power_system"]
                                
                                # Verify expected response structure
                                required_fields = [
                                    "power_source", "mechanic", "limitations", "progression",
                                    "power_metrics", "narrative_elements", "creative_suggestions"
                                ]
                                has_required = all(field in power_system for field in required_fields)
                                
                                # Verify power_source structure
                                power_source_valid = (
                                    "power_source" in power_system and
                                    all(field in power_system["power_source"] for field in ["type", "name", "description"])
                                )
                                
                                # Verify mechanic structure
                                mechanic_valid = (
                                    "mechanic" in power_system and
                                    all(field in power_system["mechanic"] for field in ["type", "name", "description"])
                                )
                                
                                # Verify limitations structure
                                limitations_valid = (
                                    "limitations" in power_system and
                                    "primary" in power_system["limitations"] and
                                    all(field in power_system["limitations"]["primary"] for field in ["type", "name", "description"])
                                )
                                
                                # Verify power metrics (6 numerical values 0.0-1.0)
                                power_metrics = power_system.get("power_metrics", {})
                                expected_metrics = [
                                    "raw_power_level", "control_precision", "cost_severity",
                                    "social_impact", "progression_speed", "uniqueness_factor"
                                ]
                                metrics_valid = (
                                    len(power_metrics) == 6 and
                                    all(metric in power_metrics for metric in expected_metrics) and
                                    all(0.0 <= power_metrics[metric] <= 1.0 for metric in expected_metrics)
                                )
                                
                                # Verify reasonable metric ranges (0.1-0.9 as specified)
                                metrics_reasonable = all(
                                    0.1 <= power_metrics[metric] <= 0.9 for metric in expected_metrics
                                ) if metrics_valid else False
                                
                                # Verify narrative elements
                                narrative_valid = (
                                    "narrative_elements" in power_system and
                                    all(field in power_system["narrative_elements"] for field in ["thematic_resonance", "societal_role", "philosophical_question"])
                                )
                                
                                # Verify creative suggestions (5 specific applications)
                                creative_suggestions = power_system.get("creative_suggestions", [])
                                suggestions_valid = isinstance(creative_suggestions, list) and len(creative_suggestions) == 5
                                
                                if (has_required and power_source_valid and mechanic_valid and 
                                    limitations_valid and metrics_valid and metrics_reasonable and 
                                    narrative_valid and suggestions_valid):
                                    success_count += 1
                                    self.log_result(f"Power System Generation ({config['name']})", True, 
                                                  "Complete power system generated successfully", {
                                                      "power_source": power_system["power_source"]["type"],
                                                      "mechanic": power_system["mechanic"]["type"],
                                                      "primary_limitation": power_system["limitations"]["primary"]["type"],
                                                      "has_secondary_limitation": power_system["limitations"].get("secondary") is not None,
                                                      "power_metrics_valid": metrics_valid,
                                                      "metrics_in_range": metrics_reasonable,
                                                      "creative_suggestions_count": len(creative_suggestions),
                                                      "thematic_coherence": bool(power_system["narrative_elements"]["thematic_resonance"])
                                                  })
                                else:
                                    self.log_result(f"Power System Generation ({config['name']})", False, 
                                                  "Invalid power system structure", {
                                                      "has_required_fields": has_required,
                                                      "power_source_valid": power_source_valid,
                                                      "mechanic_valid": mechanic_valid,
                                                      "limitations_valid": limitations_valid,
                                                      "metrics_valid": metrics_valid,
                                                      "metrics_reasonable": metrics_reasonable,
                                                      "narrative_valid": narrative_valid,
                                                      "suggestions_valid": suggestions_valid,
                                                      "suggestions_count": len(creative_suggestions)
                                                  })
                            else:
                                self.log_result(f"Power System Generation ({config['name']})", False, 
                                              "Invalid response format", data)
                        else:
                            error_text = await response.text()
                            self.log_result(f"Power System Generation ({config['name']})", False, 
                                          f"HTTP {response.status}", {"error": error_text})
                except Exception as e:
                    self.log_result(f"Power System Generation ({config['name']})", False, 
                                  f"Request error: {str(e)}")
            
            # Overall power system generation result
            if success_count == len(test_configs):
                self.log_result("Power System Generation (Overall)", True, 
                              f"All {success_count} configurations successful", {
                                  "tested_configs": len(test_configs),
                                  "successful": success_count
                              })
            else:
                self.log_result("Power System Generation (Overall)", False, 
                              f"Only {success_count}/{len(test_configs)} configurations successful", {
                                  "tested_configs": len(test_configs),
                                  "successful": success_count
                              })
                
        except Exception as e:
            self.log_result("Power System Generation (Overall)", False, f"Test setup error: {str(e)}")

    async def run_all_tests(self):
        """Run all backend tests"""
        print("üöÄ Starting VisionForge Backend Tests - Advanced Power System Framework")
        print(f"Testing against: {BACKEND_URL}")
        print("=" * 60)
        
        # Run existing tests first
        print("üìã EXISTING FEATURES:")
        await self.test_health_check()
        await self.test_get_genres()
        await self.test_ollama_models_availability()
        await self.test_text_generation()
        await self.test_style_analysis()
        await self.test_image_analysis()  # Most complex test
        await self.test_analyses_history()
        
        print("\nüÜï PHASE 2 FEATURES:")
        # Run Phase 2 tests
        await self.test_beat_sheet_types()
        await self.test_beat_sheet_generation()
        await self.test_trope_risk_analysis()
        
        print("\nüî• NEW ADVANCED POWER SYSTEM FRAMEWORK:")
        # Run new Power System Framework tests
        await self.test_power_system_themes()
        await self.test_power_system_generation()
        
        # Summary
        print("\n" + "=" * 60)
        print("üìä TEST SUMMARY")
        print("=" * 60)
        
        passed = sum(1 for result in self.test_results if result["success"])
        total = len(self.test_results)
        
        print(f"Total Tests: {total}")
        print(f"Passed: {passed}")
        print(f"Failed: {total - passed}")
        print(f"Success Rate: {(passed/total)*100:.1f}%")
        
        # Separate existing vs Phase 2 vs Power System results
        existing_tests = [r for r in self.test_results if not any(feature in r["test"] for feature in ["Beat Sheet", "Trope Risk", "Power System"])]
        phase2_tests = [r for r in self.test_results if any(phase2 in r["test"] for phase2 in ["Beat Sheet", "Trope Risk"])]
        power_system_tests = [r for r in self.test_results if "Power System" in r["test"]]
        
        existing_passed = sum(1 for r in existing_tests if r["success"])
        phase2_passed = sum(1 for r in phase2_tests if r["success"])
        power_system_passed = sum(1 for r in power_system_tests if r["success"])
        
        print(f"\nüìã EXISTING FEATURES: {existing_passed}/{len(existing_tests)} passed")
        print(f"üÜï PHASE 2 FEATURES: {phase2_passed}/{len(phase2_tests)} passed")
        print(f"üî• POWER SYSTEM FRAMEWORK: {power_system_passed}/{len(power_system_tests)} passed")
        
        if total - passed > 0:
            print("\n‚ùå FAILED TESTS:")
            for result in self.test_results:
                if not result["success"]:
                    print(f"  - {result['test']}: {result['message']}")
        
        print("\nüîç DETAILED RESULTS:")
        for result in self.test_results:
            status = "‚úÖ" if result["success"] else "‚ùå"
            print(f"{status} {result['test']}")
            if result["details"]:
                for key, value in result["details"].items():
                    print(f"    {key}: {value}")
        
        return passed == total

async def main():
    """Main test runner"""
    async with VisionForgeBackendTester() as tester:
        success = await tester.run_all_tests()
        return 0 if success else 1

if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Tests interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nüí• Test runner error: {e}")
        sys.exit(1)